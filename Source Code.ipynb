{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Source Code.ipynb","provenance":[],"collapsed_sections":["uzLJ6FYNwtT2","u8FWKEK2xJAt","3BZ5cEQOGwlD","OiuKSf8JWTcg","wfGa6fMSaLx0","oTuDEr8yCE_Q","VtK9Z-pWAPn4","ium3j4VpAgj4","XqisL3uKkZwA","pgiaLVmO8_Lx"],"toc_visible":true,"mount_file_id":"1kH8EHk23vFou_shNWScPMlCtk9i17s4r","authorship_tag":"ABX9TyMU/PrIldZ4g9yVLKlICKhu"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mrdlhDQNwqFx"},"source":["# Library"]},{"cell_type":"markdown","metadata":{"id":"uzLJ6FYNwtT2"},"source":["## PIP"]},{"cell_type":"code","metadata":{"id":"prYTd_sxwvdR","executionInfo":{"status":"ok","timestamp":1613187121515,"user_tz":-420,"elapsed":3373,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["pip install -q spacy"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EV6DDfdBwxL-","executionInfo":{"status":"ok","timestamp":1613187315318,"user_tz":-420,"elapsed":197160,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}},"outputId":"e36573cf-c607-486b-e51c-ba0a34a785d2"},"source":["!python -m spacy download en_core_web_lg"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting en_core_web_lg==2.2.5\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz (827.9MB)\n","\u001b[K     |████████████████████████████████| 827.9MB 1.1MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (53.0.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.0)\n","Building wheels for collected packages: en-core-web-lg\n","  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.2.5-cp36-none-any.whl size=829180945 sha256=439467dd468a78d996a4a00c04e738c1be09dd0081e099571df57bf27c8f3e79\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-4ozd8h8j/wheels/2a/c1/a6/fc7a877b1efca9bc6a089d6f506f16d3868408f9ff89f8dbfc\n","Successfully built en-core-web-lg\n","Installing collected packages: en-core-web-lg\n","Successfully installed en-core-web-lg-2.2.5\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_lg')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HczS4J3VuURm","executionInfo":{"status":"ok","timestamp":1613187321257,"user_tz":-420,"elapsed":203092,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}},"outputId":"a57c53df-724f-41d9-e4d2-5237a88104c4"},"source":["pip install -q git+https://github.com/LIAAD/yake"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |███▌                            | 10kB 30.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 20kB 34.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 30kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 40kB 25.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 51kB 21.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 61kB 22.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 71kB 21.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 81kB 19.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 92kB 21.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 10.3MB/s \n","\u001b[?25h  Building wheel for yake (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uH02fcKo7Tz6","executionInfo":{"status":"ok","timestamp":1613187323489,"user_tz":-420,"elapsed":205321,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["pip install -q geopy"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u8FWKEK2xJAt"},"source":["## Import"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zIvFR4CwxKtR","executionInfo":{"status":"ok","timestamp":1613187326043,"user_tz":-420,"elapsed":207870,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}},"outputId":"e4cc4f6c-e349-4e79-eb7a-d0a5480a7f36"},"source":["# System\n","from collections import Counter\n","from string import punctuation\n","import pandas as pd\n","import math\n","import statistics\n","import copy\n","import functools\n","import operator\n","import itertools\n","import re\n","import json\n","import string\n","import numpy as np\n","from datetime import datetime, date\n","from itertools import product, permutations\n","import time\n","import traceback\n","\n","# NLP\n","from nltk.corpus import stopwords, wordnet as wn\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import nltk\n","import spacy\n","import en_core_web_lg\n","import yake\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('universal_tagset')\n","\n","# Locations\n","from geopy.geocoders import Nominatim\n","\n","# Event Merging\n","from sklearn.cluster import DBSCAN\n","\n","# Evaluation\n","from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n","from geopy import distance\n","\n","# Utilities\n","from pprint import pprint"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3BZ5cEQOGwlD"},"source":["## Global Variables"]},{"cell_type":"code","metadata":{"id":"lXIVw4qWx1pa","executionInfo":{"status":"ok","timestamp":1613187335642,"user_tz":-420,"elapsed":217467,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["spacy_nlp = en_core_web_lg.load()\n","geolocator = Nominatim(user_agent=\"thesis_shandy\", timeout=None)\n","lmtzr = WordNetLemmatizer()\n","stop_words = stopwords.words('english')\n","event_merging_pairs = []"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"owke5Y4efobF"},"source":["## Global Constants"]},{"cell_type":"code","metadata":{"id":"e3YOU0CAfn4u","executionInfo":{"status":"ok","timestamp":1613188076839,"user_tz":-420,"elapsed":529,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["PATH_LOC_CITIES = \"./datasets/cities.json\"\r\n","PATH_LOC_COUNTRIES = \"./datasets/countries.csv\"\r\n","PATH_DATASET_AYLIEN = \"./datasets/aylien.json\"\r\n","PATH_EVAL_HAILSTORM = \"./evaluations/hailstorm.csv\""],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mv4uzdLwxflb"},"source":["## Global Class"]},{"cell_type":"code","metadata":{"id":"aALzOAbyxgxs","executionInfo":{"status":"ok","timestamp":1613188081225,"user_tz":-420,"elapsed":679,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["class LocationApi:\n","    # Constants\n","    PATH_CITIES = PATH_LOC_CITIES\n","    PATH_CENTROIDS = PATH_LOC_COUNTRIES\n","    df_cities = None\n","    df_countries = None\n","\n","    def __init__(self):\n","        self.initialize()\n","\n","    def initialize(self):\n","        # Initialize Cities\n","        self.df_cities = pd.read_json(self.PATH_CITIES, lines=True)\n","\n","        # Initialize countries\n","        centroids = pd.read_csv(self.PATH_CENTROIDS)\n","        self.df_countries = centroids[['name', 'Longitude', 'Latitude']]\n","\n","    # Utilities\n","    def csim_loc(self, type_loc, name):\n","        if type_loc == 'city':\n","            df = self.df_cities[self.df_cities['name'].str.startswith(name[:3].capitalize())]\n","        else: # type_loc == 'country':\n","            df = self.df_countries[self.df_countries['name'].str.startswith(name[:3].capitalize())]\n","\n","        sentences = df['name'].tolist()\n","        sentences.append(name.capitalize())\n","        vectorizer = CountVectorizer().fit_transform(sentences)\n","        vectors = vectorizer.toarray()\n","        csim = cosine_similarity(vectors)\n","        csim = csim[-1].tolist()\n","        csim.pop()\n","        return df, csim\n","\n","    def coord_loc(self, type_loc, name):\n","        df, csim = self.csim_loc(type_loc, name)\n","        df_res = df.iloc[csim.index(max(csim))]\n","        return df_res\n","\n","    # Mains\n","    def is_country(self, name):\n","        df, csim = self.csim_loc('country', name)\n","        return any(x >= 0.5 for x in csim)\n","\n","    def is_city(self, name):\n","        df, csim = self.csim_loc('city', name)\n","        return any(x >= 0.5 for x in csim)\n","\n","    def get_coord_city(self, name):\n","        df = self.coord_loc('city', name)\n","        return {\n","            \"city\": df['name'],\n","            \"country\": df['country'],\n","            \"lat\": df['lat'],\n","            \"lng\": df['lng']\n","        }\n","\n","    def get_coord_country(self, name):\n","        df = self.coord_loc('country', name)\n","        return {\n","            \"city\": \"\",\n","            \"country\": df['name'],\n","            \"lat\": df['Latitude'],\n","            \"lng\": df['Longitude']\n","        }"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OiuKSf8JWTcg"},"source":["## Helper Functions"]},{"cell_type":"code","metadata":{"id":"M4MXCkoWWXEP","executionInfo":{"status":"ok","timestamp":1613187335644,"user_tz":-420,"elapsed":217463,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["def preprocessing_text(text):\n","    text = text.lower() # Lowercase\n","    text = re.sub(r'\\d+', '', text) # Remove number\n","    text = text.translate(str.maketrans(dict.fromkeys(string.punctuation)))  \n","    text = text.strip() # Remove whitespace\n","    \n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    tokens_raw = word_tokenize(text)\n","    tokens = [i for i in tokens_raw if not i in stop_words]\n","\n","    # Lemmatization\n","    lemmatizer = WordNetLemmatizer()\n","    tokens_lemma = []\n","    for word in tokens:\n","        tokens_lemma.append(lemmatizer.lemmatize(word))\n","    return \" \".join(tokens_lemma)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"S02MRiqgUTZ_","executionInfo":{"status":"ok","timestamp":1613187335645,"user_tz":-420,"elapsed":217461,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["def days_between(d1, d2):\n","    return abs((d2 - d1).days)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"yjIDzDPp3NmG","executionInfo":{"status":"ok","timestamp":1613187335645,"user_tz":-420,"elapsed":217459,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["def ll_to_cartesian(lat, lon):\r\n","    x = np.cos(lat) * np.cos(lon)\r\n","    y = np.cos(lat) * np.sin(lon)\r\n","    z = np.sin(lat)\r\n","    return x, y, z\r\n","\r\n","def cartesian_to_ll(x, y, z):\r\n","    lon = np.arctan2(y, x)\r\n","    hyp = np.sqrt( (x*x) + (y*y))\r\n","    lat = np.arctan2(z, hyp)\r\n","    lat = lat * 180 / 3.14\r\n","    lon = lon * 180 / 3.14\r\n","    return lat, lon"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Xf-nvk87fW9"},"source":["# Implementation"]},{"cell_type":"markdown","metadata":{"id":"wfGa6fMSaLx0"},"source":["## TFIDF Dictionary"]},{"cell_type":"code","metadata":{"id":"M90k2HqaaOaO","executionInfo":{"status":"ok","timestamp":1613187335646,"user_tz":-420,"elapsed":217456,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["# Return feature names and tfidf\r\n","def create_tfidf_dict(df_news):\r\n","    corpus = [preprocessing_text(body) for body in df_news['body'].tolist()]\r\n","    vectorizer = TfidfVectorizer()\r\n","    X = vectorizer.fit_transform(corpus)\r\n","    tfidf_dict = {\r\n","        \"features\": vectorizer.get_feature_names(),\r\n","        \"scores\": X.toarray()\r\n","    }\r\n","    return tfidf_dict"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oTuDEr8yCE_Q"},"source":["## Keyword Extraction"]},{"cell_type":"code","metadata":{"id":"Lsx3ZYGgCEqV","executionInfo":{"status":"ok","timestamp":1613187335647,"user_tz":-420,"elapsed":217455,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["def keywords_extraction_original(texts):\r\n","    keywords = []\r\n","    \r\n","    extractor = yake.KeywordExtractor(n=1, top=10)\r\n","\r\n","    for text in texts:\r\n","        kw_yake = extractor.extract_keywords(text)\r\n","        kw_yake.reverse()\r\n","        kw_text = []\r\n","        for kw in kw_yake:\r\n","            kw_text.append(kw[0])\r\n","        keywords.append(kw_text)\r\n","    \r\n","    return keywords\r\n","\r\n","def keywords_extraction_enhanced(texts, tfidf_dict):\r\n","    keywords = []\r\n","    \r\n","    extractor = yake.KeywordExtractor(n=1, top=10)\r\n","\r\n","    for idx, text in enumerate(texts):\r\n","\r\n","        # Extract keyword using Yake\r\n","        kw_yake = []\r\n","        for kw in extractor.extract_keywords(text):\r\n","            try:\r\n","                kw_text = kw[0]\r\n","                kw_index = tfidf_dict['features'].index(kw_text)\r\n","                tfidf_score = tfidf_dict['scores'][idx][kw_index]\r\n","                if tfidf_score > 0.1:\r\n","                    kw_yake.append(kw_text)\r\n","            except ValueError:\r\n","                continue\r\n","                \r\n","        keywords.append(kw_yake)\r\n","\r\n","    return keywords"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VtK9Z-pWAPn4"},"source":["## Keyword Similarity"]},{"cell_type":"code","metadata":{"id":"MKRIHdbH3Kr_","executionInfo":{"status":"ok","timestamp":1613187335647,"user_tz":-420,"elapsed":217453,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["# word1 and word2 are string\r\n","def is_words_similar(word1, word2):\r\n","    # WUP\r\n","    try:\r\n","        syn1 = wn.synsets(word1)[0]\r\n","        syn2 = wn.synsets(word2)[0]\r\n","\r\n","        # Return false if one of the two words has a/r (adjective/adverb) POS\r\n","        allowed_pos = ['n', 'v']\r\n","        if (syn1.pos() not in allowed_pos) or (syn2.pos() not in allowed_pos):\r\n","            return False\r\n","\r\n","        # return false if the two words have different POS\r\n","        if syn1.pos() != syn2.pos():\r\n","            return False\r\n","\r\n","        if syn1.wup_similarity(syn2) > 0.9:\r\n","            return True\r\n","        else:\r\n","            return False\r\n","    except IndexError: # One of the keywords doesn't has meaning (ex: kenneth)\r\n","        return False"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ium3j4VpAgj4"},"source":["## Hot Event Detection"]},{"cell_type":"code","metadata":{"id":"8kynP4zvAilm","executionInfo":{"status":"ok","timestamp":1613187335648,"user_tz":-420,"elapsed":217451,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["def similarity_original(keywords_article, keywords_event):\n","    # Get the sum of weights in event keywords\n","    ev_sum = 0\n","    same_sum = 0\n","\n","    for ev_key in keywords_event:\n","        ev_sum = ev_sum + ev_key['weight']\n","\n","        for ar_key in keywords_article:\n","            if ar_key['keyword'] == ev_key['keyword']:\n","                same_sum = same_sum + ev_key['weight']\n","    \n","    try:\n","        return (same_sum/ev_sum)\n","    except ZeroDivisionError:\n","        return 0\n","\n","def similarity_enhanced(keywords_article, keywords_event):\n","    # Get the sum of weights in event keywords\n","    ev_sum = 0\n","    same_sum = 0\n","\n","    for ev_key in keywords_event:\n","        ev_sum = ev_sum + ev_key['weight']\n","\n","        for ar_key in keywords_article:\n","            if is_words_similar(ev_key['keyword'], ar_key['keyword']):\n","                same_sum = same_sum + ev_key['weight']\n","\n","    # Calculate similarity\n","    try:\n","        return(same_sum/ev_sum)\n","    except ZeroDivisionError:\n","        return 0\n","\n","def hot_event_detection(df_article, threshold, attenuation, semantic_similarity):\n","    event_library = []\n","    event_index_df = []\n","    event_index_df_sim = []\n","\n","\n","    for article_index, article in df_article.iterrows():\n","        article_keywords = article['keywords']\n","\n","        # First news is stored as an event in the event library\n","        if len(event_library) == 0:\n","            event_library.append(article_keywords)\n","            event_index_df.append(0)\n","            event_index_df_sim.append(1)\n","        else:\n","            max_sim_score = -999\n","            max_sim_event = -1\n","            \n","            # Count article similarity to each event \n","            for event_index, event_keywords in enumerate(event_library):\n","                # Count similarity\n","                if semantic_similarity == True:\n","                  sim = similarity_enhanced(article_keywords, event_keywords)\n","                else:\n","                  sim = similarity_original(article_keywords, event_keywords)\n","\n","                if sim > max_sim_score:\n","                    max_sim_score = sim\n","                    max_sim_event = event_index\n","            \n","            # Compare max similarity score to threshold\n","            if max_sim_score < threshold:\n","                # Store article as a new event\n","                event_library.append(article_keywords)\n","                event_index_df.append(len(event_library)-1)\n","                event_index_df_sim.append(1)\n","            else:\n","                # Adjust event's keywords weight\n","                changed_weight_index = [] # Get indexes of changed keywords\n","                event_keywords = event_library[max_sim_event]\n","\n","                for i in range(len(event_keywords)):\n","                    # If a keyword in event is same with a keyword in article\n","                    # Increment the weight of that event keyword weight by 1\n","                    for article_keyword in article_keywords:\n","                        event_keyword_text = event_keywords[i]['keyword']\n","                        article_keyword_text = article_keyword['keyword']\n","\n","                        if semantic_similarity == True:\n","                          if is_words_similar(event_keyword_text, article_keyword_text):\n","                              event_library[max_sim_event][i]['weight'] += 1 # Increment weight\n","                              changed_weight_index.append(i)\n","                        else:\n","                          if event_keyword_text == article_keyword_text:\n","                              event_library[max_sim_event][i]['weight'] += 1 # Increment weight\n","                              changed_weight_index.append(i)\n","                \n","                # Attenuate the rest of unchanged event keyword by attenuation rate\n","                for i in range(len(event_library[max_sim_event])):\n","                    if i in changed_weight_index:\n","                        continue\n","                    else:\n","                        event_library[max_sim_event][i]['weight'] -= attenuation\n","\n","                # Remove the keywords that have weight under attenuation rate\n","                new_keywords = []\n","                for keyword in event_library[max_sim_event]:\n","                    if keyword['weight'] > attenuation:\n","                        new_keywords.append(keyword)\n","                event_library[max_sim_event] = new_keywords\n","\n","                # Add event index to list for df\n","                event_index_df.append(max_sim_event)\n","                event_index_df_sim.append(max_sim_score)\n","                \n","\n","    df_result = df_article.copy(deep=True)\n","    df_result['event'] = event_index_df\n","    df_result['similarity'] = event_index_df_sim\n","    return df_result, dict(enumerate(event_library))"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x46qYgzTgEz0"},"source":["## Locations and Dates"]},{"cell_type":"code","metadata":{"id":"hsmrZO4uAHhx","executionInfo":{"status":"ok","timestamp":1613187335648,"user_tz":-420,"elapsed":217449,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["def ner(df_in):\n","    df_out = copy.deepcopy(df_in)\n","    locations_all = []\n","\n","    # Spacy\n","    for index, article in df_in.iterrows():\n","        doc = spacy_nlp(article['body'])\n","        locs = []\n","        for ent in doc.ents:\n","            if ent.label_ == \"GPE\":\n","                locs.append(ent.text)\n","        locations_all.append(locs)\n","    \n","    df_out['locations'] = locations_all\n","\n","    return df_out"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y0WTSrKpwG73","executionInfo":{"status":"ok","timestamp":1613187335649,"user_tz":-420,"elapsed":217447,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["def get_events_dates(df_news, events_locations):\r\n","    dates = {}\r\n","\r\n","    for cluster_idx in events_locations.keys():\r\n","        # filter news per event\r\n","        df_cluster = df_news[df_news['event'] == int(cluster_idx)]\r\n","\r\n","        potential_date = []\r\n","        for index, article in df_cluster.iterrows():\r\n","            potential_date.append(article['publication_time'].date())\r\n","\r\n","        # Get the 5 highest frequency dates (not sorted)\r\n","        five_most_common_dates = Counter(potential_date).most_common(5)\r\n","\r\n","        dates[cluster_idx] = []\r\n","        for com_date in five_most_common_dates:\r\n","            dates[cluster_idx].append(com_date)\r\n","\r\n","    return dates"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"aIS7p15efIuf","executionInfo":{"status":"ok","timestamp":1613187335650,"user_tz":-420,"elapsed":217446,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["## Locations and Times\n","def get_events_locations(df_news, events_library):\n","\n","    #\n","    # Get Locations From the 5 Highest Frequency\n","    #\n","    locations_potential = {}\n","\n","    for cluster_idx in events_library.keys():\n","        # Get articles from cluster\n","        df_cluster = df_news[df_news['event'] == int(cluster_idx)]\n","\n","        # Flatten the list then count the frequency\n","        locs = functools.reduce(operator.iconcat, df_cluster['locations'].tolist(), [])\n","        locs = [x.lower() for x in locs]\n","        locations_potential[cluster_idx] = Counter(locs).most_common(5)\n","    \n","    locations = {}\n","    locapi = LocationApi()\n","    for cluster_idx in locations_potential.keys():\n","        if locations_potential[cluster_idx] == []:\n","            continue\n","    \n","        # Convert locations text to {name, country, lat, lng}\n","        locations[cluster_idx] = []\n","        for location in locations_potential[cluster_idx]:\n","            loc = location[0].capitalize()\n","            try:\n","                if locapi.is_city(loc):\n","                    final_loc = locapi.get_coord_city(loc)\n","                    final_loc['count'] = location[1]\n","                    locations[cluster_idx].append(final_loc)\n","                elif locapi.is_country(loc):\n","                    final_loc = locapi.get_coord_country(loc)\n","                    final_loc['count'] = location[1]\n","                    locations[cluster_idx].append(final_loc)\n","                else:\n","                    georesult = geolocator.geocode(loc, language='en')\n","                    if georesult is not None:\n","                        locations[cluster_idx].append({\n","                            \"city\": loc,\n","                            \"country\": georesult.address.split(\", \")[-1],\n","                            \"lat\": georesult.latitude,\n","                            \"lng\": georesult.longitude,\n","                            \"count\": location[1]\n","                        })\n","            except ValueError:\n","                continue\n","\n","    return locations"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ap4BHQq-gQMp"},"source":["## Event Merging"]},{"cell_type":"code","metadata":{"id":"vAWzLXIG3mDu","executionInfo":{"status":"ok","timestamp":1613187335650,"user_tz":-420,"elapsed":217444,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["def get_events_location_merging(events_library):\r\n","    for ev_key in events_library.keys():\r\n","        # Get dates with highest freq\r\n","        highest_freq = events_library[ev_key]['locations'][0]['count'] # Locations already sorted from highest freq\r\n","        highest_freq_list = []\r\n","        for loc in events_library[ev_key]['locations']:\r\n","            if loc['count'] == highest_freq:\r\n","                highest_freq_list.append(loc)\r\n","        \r\n","        events_library[ev_key]['loc_lat'] = highest_freq_list[0]['lat']\r\n","        events_library[ev_key]['loc_lng'] = highest_freq_list[0]['lng']\r\n","\r\n","    return events_library\r\n","\r\n","def get_events_date_merging(df_news, events_library):\r\n","    for ev_key in events_library.keys():\r\n","        # Get dates with highest freq\r\n","        highest_freq = events_library[ev_key]['dates'][0][1] # Dates already sorted from highest freq\r\n","        highest_freq_list = []\r\n","        for date in events_library[ev_key]['dates']:\r\n","            if date[1] == highest_freq:\r\n","                highest_freq_list.append(date)\r\n","        \r\n","        # If date with highest freq only 1, use it\r\n","        if len(highest_freq_list) == 1:\r\n","            events_library[ev_key]['highest_freq_date'] = highest_freq_list[0][0]\r\n","        # More than one dates with the highest freq\r\n","        elif len(highest_freq_list) > 1:\r\n","            sim_freq = []\r\n","            for com_date in highest_freq_list:\r\n","                # Get all news in the cluster with the date\r\n","                df_cluster = df_news[df_news['event'] == int(ev_key)]\r\n","                df_date = df_cluster[df_cluster['publication_time'].dt.strftime('%Y-%m-%d') == com_date[0]]\r\n","\r\n","                # Count the relevances mean\r\n","                sim_freq.append((com_date[0], com_date[1], df_date['similarity'].mean()))\r\n","\r\n","            # Sort based on similarity inplace\r\n","            sim_freq.sort(key=lambda tup: tup[-1], reverse=True)\r\n","            events_library[ev_key]['highest_freq_date'] = sim_freq[0][0]\r\n","\r\n","    return events_library"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"Auh_wkNeVIHx","executionInfo":{"status":"ok","timestamp":1613187335651,"user_tz":-420,"elapsed":217442,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["def detect_merge(event_lib):\n","    merge_potential = []\n","    event_lib = event_lib.sort_values('highest_freq_date')\n","    i = 0\n","    j = 1\n","    for idx1, row1 in event_lib.iterrows():\n","        for idx2, row2 in event_lib.iterrows():\n","            if idx1 != idx2:\n","                distance_date = days_between(row1['highest_freq_date'], row2['highest_freq_date'])\n","                loc1 = (row1['loc_lat'], row1['loc_lng'])\n","                loc2 = (row2['loc_lat'], row2['loc_lng'])\n","                distance_location = distance.distance(loc1, loc2).km\n","                if distance_date <= 2 and distance_location <= 50:\n","                    merge_potential.append((idx1,idx2))\n","                    event_merging_pairs.append({\n","                        \"loc1\": {\n","                            \"lat\": row1['loc_lat'],\n","                            \"lng\": row1['loc_lng'],\n","                            \"date\": row1['highest_freq_date']\n","                        },\n","                        \"loc2\": {\n","                            \"lat\": row2['loc_lat'],\n","                            \"lng\": row2['loc_lng'],\n","                            \"date\": row2['highest_freq_date']\n","                        },\n","                        \"distance\": {\n","                            \"location\": distance_location,\n","                            \"date\": distance_date\n","                        }\n","                    })\n","\n","\n","    return list(set(tuple(sorted(l)) for l in merge_potential))"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrouVM73gdM8","executionInfo":{"status":"ok","timestamp":1613187335651,"user_tz":-420,"elapsed":217440,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["def get_merge_potential(df_news, events_library):\n","    events_library = get_events_location_merging(events_library)\n","    events_library = get_events_date_merging(df_news, events_library)\n","    lib_temp = pd.DataFrame.from_dict(events_library, orient='index')\n","\n","    # Cluster per location using KMeans with n_clusters/2\n","    ev_locs = []\n","    for ev_key in events_library.keys():\n","        lat = events_library[ev_key]['loc_lat']\n","        lng = events_library[ev_key]['loc_lng']\n","        ev_locs.append([lat, lng])\n","    \n","    # DBSCAN\n","    clustering = DBSCAN(eps=10, min_samples=1).fit(ev_locs)\n","    lib_temp['merging_locs'] = clustering.labels_\n","\n","    # Cluster time per location cluster\n","    to_merge_list = []\n","    for loc in list(set(clustering.labels_)):\n","        event_temp = lib_temp[lib_temp['merging_locs'] == loc] # Filter per location cluster\n","        to_merge_list.append(detect_merge(event_temp))\n","    \n","    to_merge_list_flat = [item for sublist in to_merge_list for item in sublist] # Flatten to merge list\n","    to_merge_list_flat.sort()\n","\n","    return to_merge_list_flat "],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3roZG-Q9DjK","executionInfo":{"status":"ok","timestamp":1613187335652,"user_tz":-420,"elapsed":217439,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["def ev_merging(df_news, events_library, events_locations):\r\n","    to_merge_pairs = get_merge_potential(df_news, events_library) # Get pairs of similar event clusters\r\n","    events_list = df_news['event'].tolist()\r\n","\r\n","    # Renewing event column in df_news\r\n","    if to_merge_pairs != []:\r\n","        new_idxs = []\r\n","        for idx_pair in range(len(to_merge_pairs)-1, -1, -1):\r\n","            old_idx = to_merge_pairs[idx_pair][1]\r\n","            new_idx = to_merge_pairs[idx_pair][0]\r\n","            events_library[new_idx]['locations'] = events_library[new_idx]['locations'] + events_library[old_idx]['locations']\r\n","            events_library[new_idx]['dates'] = events_library[new_idx]['dates'] + events_library[old_idx]['dates']\r\n","            events_list = [new_idx if idx==old_idx else idx for idx in events_list]\r\n","        df_news['event'] = events_list\r\n","    \r\n","    # For news in events without locations, assign event with -1\r\n","    for idx, news in df_news.iterrows():\r\n","        if news['event'] not in events_locations.keys():\r\n","            df_news.at[idx, 'event'] = -1\r\n","\r\n","    # Delete clusters without news in event library\r\n","    to_delete_clusters = []\r\n","    for cluster_idx in events_library.keys():\r\n","        if len(df_news[df_news['event'] == cluster_idx]) == 0:\r\n","            try:\r\n","                to_delete_clusters.append(cluster_idx)\r\n","            except KeyError:\r\n","                continue\r\n","    for cluster_idx in to_delete_clusters:\r\n","        try:\r\n","            del events_library[cluster_idx]\r\n","        except KeyError:\r\n","            continue\r\n","\r\n","    return df_news, events_library"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b0V6bdMBgU1U"},"source":["## Main"]},{"cell_type":"code","metadata":{"id":"5dlbpQe7Z8YH","executionInfo":{"status":"ok","timestamp":1613187335652,"user_tz":-420,"elapsed":217435,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["def main_enhanced(path, threshold, attenuation, query='', keywords_analysis=True, semantic_similarity=True, event_merging=True):\n","    # Starting perf counter\n","    time_start = time.perf_counter()\n","\n","    # Read News Dataset\n","    print(\"PROCESS:\\t Reading dataset...\")\n","    df_news = pd.read_json(path, orient='records')\n","\n","    # News' body filter feature\n","    print(\"PROCESS:\\t Filtering news with query...\")\n","    if query != '':\n","        df_news = df_news[df_news['body'].str.contains(pat=query, case=False)]\n","        df_news = df_news.reset_index(drop=True)\n","\n","    print(\"RESULT:\\t\\t Detected\", df_news.shape[0], \" with\", query, \"topic\")\n","\n","    # Keywords Extraction\n","    if keywords_analysis == True:\n","      # Creating TFIDF Dictionary\n","      print(\"PROCESS:\\t Extracting and Analyzing Keywords...\")\n","      tfidf_dict = create_tfidf_dict(df_news)\n","      df_keywords = keywords_extraction_enhanced(df_news['body'], tfidf_dict=tfidf_dict)\n","    else:\n","      print(\"PROCESS:\\t Extracting keywords...\")\n","      df_keywords = keywords_extraction_original(df_news['body'])\n","\n","    print(\"PROCESS:\\t Initializing Keyword's weights...\")\n","    df_keywords_weight = []\n","    for keywords in df_keywords:\n","        weighted_keywords = [] # {\"keyword\":<keyword>, \"weight\":<weight>}\n","        for keyword in keywords:\n","            weighted_keywords.append({\n","                \"keyword\": keyword,\n","                \"weight\": 1\n","            })\n","        \n","        df_keywords_weight.append(weighted_keywords)\n","\n","    df_news['keywords'] = df_keywords_weight\n","\n","    # Hot Event Detection (Modified)\n","    print(\"PROCESS:\\t Detecting events...\")\n","    df_news, events_library = hot_event_detection(df_news, threshold, attenuation, semantic_similarity)\n","    df_news['keywords'] = df_keywords\n","    if event_merging == True:\n","        print(\"RESULT:\\t\\t Detected\", len(df_news['event'].unique())-1, \"events (before event merging)\")\n","    else:\n","        print(\"RESULT:\\t\\t Detected\", len(df_news['event'].unique())-1, \"events\")\n","\n","     # Getting locations and time\n","    print(\"RESULT:\\t\\t Getting locations and times...\")\n","    df_news = ner(df_news) # Getting location(s) and time(s) per document\n","    events_locations = get_events_locations(df_news, events_library)\n","    \n","    # Remove events that doesn't have locations\n","    to_remove_events = []\n","    for ev_key in events_locations.keys():\n","        detected_events = df_news['event'].tolist()\n","        if events_locations[ev_key] == []:\n","            to_remove_events.append(ev_key)\n","            new_events = [-1 if x==ev_key else x for x in detected_events]\n","            df_news['event'] = new_events\n","    for ev_key in to_remove_events:\n","        try:\n","            del events_locations[ev_key]\n","        except KeyError:\n","            continue\n","\n","    events_dates = get_events_dates(df_news, events_locations)\n","    events_library_v2 = {}\n","    for ev_key in events_locations.keys():\n","        events_library_v2[ev_key] = {\n","            \"keywords\" : events_library[ev_key],\n","            \"dates\": events_dates[ev_key],\n","            \"locations\": events_locations[ev_key]\n","        }\n","\n","    if event_merging == True:\n","        print(\"PROCESS:\\t Event Merging...\")\n","        df_news, events_library_v3 = ev_merging(df_news, events_library_v2, events_locations)\n","        print(\"RESULT:\\t\\t Number of events after event merging: \", len(df_news['event'].unique())-1, \"events (after event merging)\")\n","\n","    # # Stopping perf counter\n","    time_stop = time.perf_counter()\n","    print(\"== Code finished in {} second(s)\".format(str(time_stop-time_start)), \"==\")\n","\n","    if event_merging == True:\n","        return df_news, pd.DataFrame.from_dict(events_library_v3, orient='index')\n","    else:\n","        return df_news, pd.DataFrame.from_dict(events_library_v2, orient='index')"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8pDHQfIHPGuD"},"source":["## Run"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"id":"Q3YUu56znb1i","executionInfo":{"status":"error","timestamp":1613187854487,"user_tz":-420,"elapsed":1100,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}},"outputId":"8f8c9b27-ed44-43b5-f128-64f635af3bc6"},"source":["event_merging_pairs = []\n","enhanced_df, enhanced_library = main_enhanced(path=PATH_DATASET_AYLIEN,\n","                                            threshold=0.2,\n","                                            attenuation=0.1,\n","                                            query='hailstorm',\n","                                            keywords_analysis=True,\n","                                            semantic_similarity=True,\n","                                            event_merging=True)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["PROCESS:\t Reading dataset...\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-1f5d3f490ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                                             \u001b[0mkeywords_analysis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                             \u001b[0msemantic_similarity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                             event_merging=True)\n\u001b[0m","\u001b[0;32m<ipython-input-22-1c553a0aa881>\u001b[0m in \u001b[0;36mmain_enhanced\u001b[0;34m(path, threshold, attenuation, query, keywords_analysis, semantic_similarity, event_merging)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Read News Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PROCESS:\\t Reading dataset...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf_news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# News' body filter feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows)\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1138\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m             )\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected object or value"]}]},{"cell_type":"code","metadata":{"id":"s8CGNWN1gtYj","executionInfo":{"status":"ok","timestamp":1613188243242,"user_tz":-420,"elapsed":1308,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}}},"source":["!pip freeze > requirements.txt"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qimSWkIDT8Vl"},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{"id":"XqisL3uKkZwA"},"source":["## Metric"]},{"cell_type":"code","metadata":{"id":"EjtR8B5oT66R"},"source":["def evaluations(news_bodies, event_labels):\n","    tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocessing_text)\n","    tfidf = tfidf_vectorizer.fit_transform(news_bodies)\n","\n","    print(\"Silhouette \\t\\t: \", silhouette_score(tfidf.toarray(), event_labels, metric='euclidean'), \"\\t (Best is 1, Worst is -1, Near 0 means overlapping clusters)\")\n","    print(\"Calinski Harabasz \\t: \", calinski_harabasz_score(tfidf.toarray(), event_labels), \"\\t (Higher is better) \")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ot-Bptxse3c9","executionInfo":{"status":"ok","timestamp":1612997320174,"user_tz":-420,"elapsed":2642,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}},"outputId":"58775da7-62b3-4c44-b9ea-222de3dd4a84"},"source":["# With Keyword Analysis (TFIDF) and Event Merging\n","evaluations(enhanced_df['body'], enhanced_df['event'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Silhouette \t\t:  0.10820777407007456 \t (Best is 1, Worst is -1, Near 0 means overlapping clusters)\n","Calinski Harabasz \t:  2.2303812193838257 \t\t (Higher is better) \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cvzlj-8gkbvi"},"source":["## Time-Location"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"id":"PNl1BJqRKe1l","executionInfo":{"status":"error","timestamp":1613188088778,"user_tz":-420,"elapsed":739,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}},"outputId":"efd75119-fc6a-4031-f6c7-dd865440e751"},"source":["eval_hailstorm = pd.read_csv(PATH_EVAL_HAILSTORM, skipinitialspace=True, parse_dates=['time'])\r\n","eval_hailstorm['time'] = pd.to_datetime(eval_hailstorm['time'], format='%Y-%m-%d')\r\n","eval_hailstorm.head()"],"execution_count":27,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-9a18010491b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_hailstorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_EVAL_HAILSTORM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipinitialspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0meval_hailstorm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_hailstorm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meval_hailstorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './evaluations/hailstorm.csv'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kRc0Pnhr4shT","executionInfo":{"status":"ok","timestamp":1612998966042,"user_tz":-420,"elapsed":1463,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}},"outputId":"fd36ad28-af50-482f-d6ee-53f5bbc03063"},"source":["detected = len(enhanced_library)\r\n","ground = len(eval_hailstorm)\r\n","intersect = 0\r\n","\r\n","for lib_idx, lib_df in enhanced_library.iterrows():\r\n","    for gnd_idx, gnd_df in eval_hailstorm.iterrows():\r\n","        loc_gnd = gnd_df['location']\r\n","\r\n","        is_location_true = False\r\n","        is_date_true = False\r\n","        for loc_df in lib_df['locations']:\r\n","            if loc_gnd == loc_df['city']:\r\n","                is_location_true = True \r\n","                break\r\n","        \r\n","        for date_df in lib_df['dates']:\r\n","            if days_between(date_df[0], gnd_df['time'].date()) <= 3:\r\n","                is_date_true = True\r\n","\r\n","        if is_location_true and is_date_true: # ( days_between(lib_df['highest_freq_date'], gnd_df['time'].date()) <= 3):\r\n","            intersect = intersect + 1\r\n","            print(lib_idx, loc_df, \":\", lib_df['dates'], \" - \", gnd_df['time'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 {'city': 'Potohar', 'country': 'Pakistan', 'lat': 33.6195827, 'lng': 73.0657654, 'count': 4} : [(datetime.date(2019, 5, 5), 1)]  -  2019-05-05 00:00:00\n","1 {'city': 'Las Vegas', 'country': 'Honduras', 'lat': 15.01667, 'lng': -87.45, 'count': 2} : [(datetime.date(2019, 5, 8), 1)]  -  2019-05-08 00:00:00\n","3 {'city': 'Sindh', 'country': 'Pakistan', 'lat': 25.5, 'lng': 69.0, 'count': 2} : [(datetime.date(2019, 5, 17), 1)]  -  2019-05-17 00:00:00\n","4 {'city': 'Jaisalmer', 'country': 'India', 'lat': 26.91763, 'lng': 70.90387, 'count': 4} : [(datetime.date(2019, 5, 17), 1)]  -  2019-05-17 00:00:00\n","5 {'city': 'Vermilion', 'country': 'Canada', 'lat': 53.35409, 'lng': -110.85849, 'count': 1} : [(datetime.date(2019, 5, 17), 1)]  -  2019-05-16 00:00:00\n","6 {'city': 'Delhi', 'country': 'India', 'lat': 28.65195, 'lng': 77.23149, 'count': 5} : [(datetime.date(2019, 5, 17), 1)]  -  2019-05-17 00:00:00\n","12 {'city': 'Abbottabad', 'country': 'Pakistan', 'lat': 34.1463, 'lng': 73.21168, 'count': 3} : [(datetime.date(2019, 5, 25), 1)]  -  2019-05-25 00:00:00\n","13 {'city': 'Abbottabad', 'country': 'Pakistan', 'lat': 34.1463, 'lng': 73.21168, 'count': 1} : [(datetime.date(2019, 5, 25), 1)]  -  2019-05-25 00:00:00\n","13 {'city': 'Lahore', 'country': 'Pakistan', 'lat': 31.558, 'lng': 74.35071, 'count': 1} : [(datetime.date(2019, 5, 25), 1)]  -  2019-05-25 00:00:00\n","15 {'city': 'Beijing', 'country': 'China', 'lat': 39.9075, 'lng': 116.39723, 'count': 7} : [(datetime.date(2019, 11, 27), 2), (datetime.date(2019, 5, 27), 1), (datetime.date(2019, 5, 29), 1), (datetime.date(2019, 6, 26), 1)]  -  2019-05-28 00:00:00\n","15 {'city': 'Lusaka', 'country': 'Zambia', 'lat': -15.40669, 'lng': 28.28713, 'count': 6} : [(datetime.date(2019, 11, 27), 2), (datetime.date(2019, 5, 27), 1), (datetime.date(2019, 5, 29), 1), (datetime.date(2019, 6, 26), 1)]  -  2019-11-27 00:00:00\n","16 {'city': 'Beijing', 'country': 'China', 'lat': 39.9075, 'lng': 116.39723, 'count': 1} : [(datetime.date(2019, 5, 27), 1)]  -  2019-05-28 00:00:00\n","17 {'city': 'Beijing', 'country': 'China', 'lat': 39.9075, 'lng': 116.39723, 'count': 4} : [(datetime.date(2019, 5, 28), 2)]  -  2019-05-28 00:00:00\n","18 {'city': 'Ohio', 'country': 'United States', 'lat': 40.2253569, 'lng': -82.6881395, 'count': 6} : [(datetime.date(2019, 5, 28), 2)]  -  2019-05-28 00:00:00\n","19 {'city': 'Ohio', 'country': 'United States', 'lat': 40.2253569, 'lng': -82.6881395, 'count': 12} : [(datetime.date(2019, 5, 28), 1)]  -  2019-05-28 00:00:00\n","21 {'city': 'Odisha', 'country': 'India', 'lat': 20.5431241, 'lng': 84.6897321, 'count': 1} : [(datetime.date(2019, 6, 3), 1)]  -  2019-06-02 00:00:00\n","23 {'city': 'Ahmednagar', 'country': 'India', 'lat': 19.162772500000003, 'lng': 74.85802430085195, 'count': 4} : [(datetime.date(2019, 6, 5), 1), (datetime.date(2019, 6, 6), 1)]  -  2019-06-05 00:00:00\n","25 {'city': 'Bavaria', 'country': 'Germany', 'lat': 48.9467562, 'lng': 11.4038717, 'count': 2} : [(datetime.date(2019, 6, 10), 1)]  -  2019-06-10 00:00:00\n","31 {'city': 'Wichita', 'country': 'United States', 'lat': 37.69224, 'lng': -97.33754, 'count': 3} : [(datetime.date(2019, 6, 19), 1)]  -  2019-06-18 00:00:00\n","33 {'city': 'Maharashtra', 'country': 'India', 'lat': 18.9068356, 'lng': 75.6741579, 'count': 3} : [(datetime.date(2019, 6, 29), 1)]  -  2019-06-29 00:00:00\n","34 {'city': 'Guadalajara', 'country': 'Spain', 'lat': 40.62862, 'lng': -3.16185, 'count': 1} : [(datetime.date(2019, 7, 1), 1)]  -  2019-07-01 00:00:00\n","35 {'city': 'Guadalajara', 'country': 'Spain', 'lat': 40.62862, 'lng': -3.16185, 'count': 67} : [(datetime.date(2019, 7, 1), 17), (datetime.date(2019, 7, 2), 5), (datetime.date(2019, 7, 5), 1)]  -  2019-07-01 00:00:00\n","36 {'city': 'Maharashtra', 'country': 'India', 'lat': 18.9068356, 'lng': 75.6741579, 'count': 3} : [(datetime.date(2019, 7, 1), 1)]  -  2019-06-29 00:00:00\n","39 {'city': 'Italy', 'country': 'United States', 'lat': 32.18404, 'lng': -96.88472, 'count': 1} : [(datetime.date(2019, 7, 7), 1)]  -  2019-07-07 00:00:00\n","42 {'city': 'Italy', 'country': 'United States', 'lat': 32.18404, 'lng': -96.88472, 'count': 6} : [(datetime.date(2019, 7, 9), 2), (datetime.date(2019, 9, 19), 1)]  -  2019-07-07 00:00:00\n","43 {'city': 'Halkidiki', 'country': 'Greece', 'lat': 40.28948215, 'lng': 23.409392443373925, 'count': 3} : [(datetime.date(2019, 7, 10), 2), (datetime.date(2019, 7, 11), 1)]  -  2019-07-10 00:00:00\n","44 {'city': 'Halkidiki', 'country': 'Greece', 'lat': 40.28948215, 'lng': 23.409392443373925, 'count': 3} : [(datetime.date(2019, 7, 11), 2)]  -  2019-07-10 00:00:00\n","46 {'city': 'Halkidiki', 'country': 'Greece', 'lat': 40.28948215, 'lng': 23.409392443373925, 'count': 9} : [(datetime.date(2019, 7, 11), 11), (datetime.date(2019, 7, 12), 1)]  -  2019-07-10 00:00:00\n","48 {'city': 'Halkidiki', 'country': 'Greece', 'lat': 40.28948215, 'lng': 23.409392443373925, 'count': 1} : [(datetime.date(2019, 7, 11), 1)]  -  2019-07-10 00:00:00\n","50 {'city': 'Stanthorpe', 'country': 'Australia', 'lat': -28.65425, 'lng': 151.93388, 'count': 1} : [(datetime.date(2019, 7, 22), 1)]  -  2019-07-22 00:00:00\n","58 {'city': 'Rome', 'country': 'Italy', 'lat': 41.89193, 'lng': 12.511330000000001, 'count': 2} : [(datetime.date(2019, 8, 11), 1)]  -  2019-08-11 00:00:00\n","59 {'city': 'Rome', 'country': 'Italy', 'lat': 41.89193, 'lng': 12.511330000000001, 'count': 6} : [(datetime.date(2019, 8, 13), 1)]  -  2019-08-11 00:00:00\n","60 {'city': 'Pennsylvania', 'country': 'United States', 'lat': 40.9699889, 'lng': -77.7278831, 'count': 4} : [(datetime.date(2019, 8, 19), 1)]  -  2019-08-19 00:00:00\n","62 {'city': 'Montana', 'country': 'Bulgaria', 'lat': 43.4125, 'lng': 23.225, 'count': 1} : [(datetime.date(2019, 8, 21), 1)]  -  2019-08-19 00:00:00\n","64 {'city': 'Mallorca', 'country': 'Spain', 'lat': 39.6134018, 'lng': 2.8804305326400756, 'count': 4} : [(datetime.date(2019, 8, 28), 1)]  -  2019-08-28 00:00:00\n","67 {'city': 'Florida', 'country': 'Colombia', 'lat': 3.3223000000000003, 'lng': -76.2348, 'count': 44} : [(datetime.date(2019, 9, 1), 1), (datetime.date(2019, 9, 2), 1)]  -  2019-09-01 00:00:00\n","68 {'city': 'Kisumu', 'country': 'Kenya', 'lat': -0.10221000000000001, 'lng': 34.76171, 'count': 2} : [(datetime.date(2019, 9, 3), 1)]  -  2019-09-02 00:00:00\n","70 {'city': 'Comboyne', 'country': 'Australia', 'lat': -31.6055232, 'lng': 152.468029, 'count': 1} : [(datetime.date(2019, 9, 18), 1)]  -  2019-09-18 00:00:00\n","74 {'city': 'Wairoa', 'country': 'New Zealand', 'lat': -39.03333, 'lng': 177.36667, 'count': 1} : [(datetime.date(2019, 10, 1), 1)]  -  2019-10-01 00:00:00\n","75 {'city': 'Katlang', 'country': 'Pakistan', 'lat': 34.3597379, 'lng': 72.0759036, 'count': 6} : [(datetime.date(2019, 10, 2), 2)]  -  2019-10-02 00:00:00\n","81 {'city': 'Queensland', 'country': 'Australia', 'lat': -22.1646782, 'lng': 144.5844903, 'count': 5} : [(datetime.date(2019, 10, 11), 2)]  -  2019-10-11 00:00:00\n","84 {'city': 'Hisar', 'country': 'India', 'lat': 29.15394, 'lng': 75.72294, 'count': 2} : [(datetime.date(2019, 10, 20), 1)]  -  2019-10-18 00:00:00\n","85 {'city': 'Queensland', 'country': 'Australia', 'lat': -22.1646782, 'lng': 144.5844903, 'count': 2} : [(datetime.date(2019, 10, 26), 2)]  -  2019-10-26 00:00:00\n","88 {'city': 'Islamabad', 'country': 'Pakistan', 'lat': 33.72148, 'lng': 73.04329, 'count': 2} : [(datetime.date(2019, 11, 6), 1)]  -  2019-11-06 00:00:00\n","91 {'city': 'Barmer', 'country': 'India', 'lat': 25.5819034, 'lng': 71.61966242777196, 'count': 2} : [(datetime.date(2019, 11, 15), 1)]  -  2019-11-14 00:00:00\n","91 {'city': 'Rajasthan', 'country': 'India', 'lat': 26.8105777, 'lng': 73.7684549, 'count': 2} : [(datetime.date(2019, 11, 15), 1)]  -  2019-11-15 00:00:00\n","93 {'city': 'Rajasthan', 'country': 'India', 'lat': 26.8105777, 'lng': 73.7684549, 'count': 1} : [(datetime.date(2019, 11, 17), 1)]  -  2019-11-15 00:00:00\n","94 {'city': 'Christchurch', 'country': 'United Kingdom', 'lat': 50.73583, 'lng': -1.78129, 'count': 2} : [(datetime.date(2019, 11, 18), 1)]  -  2019-11-18 00:00:00\n","95 {'city': 'Lusaka', 'country': 'Zambia', 'lat': -15.40669, 'lng': 28.28713, 'count': 1} : [(datetime.date(2019, 11, 29), 1)]  -  2019-11-27 00:00:00\n","97 {'city': 'Uttarakhand', 'country': 'India', 'lat': 30.0417376, 'lng': 79.089691, 'count': 2} : [(datetime.date(2019, 12, 13), 1)]  -  2019-12-13 00:00:00\n","99 {'city': 'Nagaur', 'country': 'India', 'lat': 27.0607859, 'lng': 74.17667537582712, 'count': 2} : [(datetime.date(2019, 12, 15), 3)]  -  2019-12-13 00:00:00\n","100 {'city': 'Woodside', 'country': 'Australia', 'lat': -34.95433, 'lng': 138.87901, 'count': 35} : [(datetime.date(2019, 12, 22), 1)]  -  2019-12-22 00:00:00\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"la48Gp9VMvuN","executionInfo":{"status":"ok","timestamp":1612998969892,"user_tz":-420,"elapsed":652,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}},"outputId":"60c24f66-8162-4806-d077-939858c7b20a"},"source":["print(\"ground \\t\\t: \", ground)\r\n","print(\"detected \\t: \", detected)\r\n","print(\"intersect \\t: \", intersect)\r\n","\r\n","precision = intersect/detected\r\n","recall = intersect/ground\r\n","fscore = 2*( (precision*recall)/(precision+recall) )\r\n","\r\n","print(\"precision \\t: \", precision)\r\n","print(\"recall \\t\\t: \", recall)\r\n","print(\"F-Score \\t: \", fscore)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ground \t\t:  61\n","detected \t:  100\n","intersect \t:  52\n","precision \t:  0.52\n","recall \t\t:  0.8524590163934426\n","F-Score \t:  0.6459627329192545\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pgiaLVmO8_Lx"},"source":["## Event Merging"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wwapjX-k9A5r","executionInfo":{"status":"ok","timestamp":1612171950900,"user_tz":-420,"elapsed":809,"user":{"displayName":"Shandy 13516097","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4NMtcbEg9Bodyum3ZVDHLT1iRPzl0fPm6JF-6=s64","userId":"01400387015952751825"}},"outputId":"d124d4de-7036-4f85-a21a-42bdc0409c46"},"source":["sorted(event_merging_pairs, key=lambda x: x['distance']['location'], reverse=True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'distance': {'date': 0, 'location': 49.62682665083389},\n","  'loc1': {'date': datetime.date(2019, 5, 25),\n","   'lat': 33.72148,\n","   'lng': 73.04329},\n","  'loc2': {'date': datetime.date(2019, 5, 25),\n","   'lat': 34.1463,\n","   'lng': 73.21168}},\n"," {'distance': {'date': 0, 'location': 49.62682665083389},\n","  'loc1': {'date': datetime.date(2019, 5, 25),\n","   'lat': 34.1463,\n","   'lng': 73.21168},\n","  'loc2': {'date': datetime.date(2019, 5, 25),\n","   'lat': 33.72148,\n","   'lng': 73.04329}},\n"," {'distance': {'date': 2, 'location': 20.403404836793243},\n","  'loc1': {'date': datetime.date(2019, 11, 15),\n","   'lat': 23.3880846,\n","   'lng': 70.173166},\n","  'loc2': {'date': datetime.date(2019, 11, 17),\n","   'lat': 23.3040626,\n","   'lng': 70.3507333}},\n"," {'distance': {'date': 2, 'location': 20.403404836793243},\n","  'loc1': {'date': datetime.date(2019, 11, 17),\n","   'lat': 23.3040626,\n","   'lng': 70.3507333},\n","  'loc2': {'date': datetime.date(2019, 11, 15),\n","   'lat': 23.3880846,\n","   'lng': 70.173166}},\n"," {'distance': {'date': 2, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 6, 29),\n","   'lat': 18.9068356,\n","   'lng': 75.6741579},\n","  'loc2': {'date': datetime.date(2019, 7, 1),\n","   'lat': 18.9068356,\n","   'lng': 75.6741579}},\n"," {'distance': {'date': 2, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 7, 1),\n","   'lat': 18.9068356,\n","   'lng': 75.6741579},\n","  'loc2': {'date': datetime.date(2019, 6, 29),\n","   'lat': 18.9068356,\n","   'lng': 75.6741579}},\n"," {'distance': {'date': 0, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 7, 31),\n","   'lat': 34.54426,\n","   'lng': -91.96903},\n","  'loc2': {'date': datetime.date(2019, 7, 31),\n","   'lat': 34.54426,\n","   'lng': -91.96903}},\n"," {'distance': {'date': 0, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 7, 31),\n","   'lat': 34.54426,\n","   'lng': -91.96903},\n","  'loc2': {'date': datetime.date(2019, 7, 31),\n","   'lat': 34.54426,\n","   'lng': -91.96903}},\n"," {'distance': {'date': 2, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 8, 11),\n","   'lat': 41.89193,\n","   'lng': 12.511330000000001},\n","  'loc2': {'date': datetime.date(2019, 8, 13),\n","   'lat': 41.89193,\n","   'lng': 12.511330000000001}},\n"," {'distance': {'date': 2, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 8, 13),\n","   'lat': 41.89193,\n","   'lng': 12.511330000000001},\n","  'loc2': {'date': datetime.date(2019, 8, 11),\n","   'lat': 41.89193,\n","   'lng': 12.511330000000001}},\n"," {'distance': {'date': 1, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 7, 10),\n","   'lat': 43.20978,\n","   'lng': -77.69306},\n","  'loc2': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306}},\n"," {'distance': {'date': 1, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 7, 10),\n","   'lat': 43.20978,\n","   'lng': -77.69306},\n","  'loc2': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306}},\n"," {'distance': {'date': 1, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 7, 10),\n","   'lat': 43.20978,\n","   'lng': -77.69306},\n","  'loc2': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306}},\n"," {'distance': {'date': 1, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306},\n","  'loc2': {'date': datetime.date(2019, 7, 10),\n","   'lat': 43.20978,\n","   'lng': -77.69306}},\n"," {'distance': {'date': 0, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306},\n","  'loc2': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306}},\n"," {'distance': {'date': 0, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306},\n","  'loc2': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306}},\n"," {'distance': {'date': 1, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306},\n","  'loc2': {'date': datetime.date(2019, 7, 10),\n","   'lat': 43.20978,\n","   'lng': -77.69306}},\n"," {'distance': {'date': 0, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306},\n","  'loc2': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306}},\n"," {'distance': {'date': 0, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306},\n","  'loc2': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306}},\n"," {'distance': {'date': 1, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306},\n","  'loc2': {'date': datetime.date(2019, 7, 10),\n","   'lat': 43.20978,\n","   'lng': -77.69306}},\n"," {'distance': {'date': 0, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306},\n","  'loc2': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306}},\n"," {'distance': {'date': 0, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306},\n","  'loc2': {'date': datetime.date(2019, 7, 11),\n","   'lat': 43.20978,\n","   'lng': -77.69306}},\n"," {'distance': {'date': 2, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 12, 13),\n","   'lat': 26.8105777,\n","   'lng': 73.7684549},\n","  'loc2': {'date': datetime.date(2019, 12, 15),\n","   'lat': 26.8105777,\n","   'lng': 73.7684549}},\n"," {'distance': {'date': 2, 'location': 0.0},\n","  'loc1': {'date': datetime.date(2019, 12, 15),\n","   'lat': 26.8105777,\n","   'lng': 73.7684549},\n","  'loc2': {'date': datetime.date(2019, 12, 13),\n","   'lat': 26.8105777,\n","   'lng': 73.7684549}}]"]},"metadata":{"tags":[]},"execution_count":150}]}]}